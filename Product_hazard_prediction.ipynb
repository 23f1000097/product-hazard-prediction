{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Import Libraries"
      ],
      "metadata": {
        "id": "Uv7vN1HXkHGm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.utils.class_weight import compute_class_weight"
      ],
      "metadata": {
        "id": "jsrX6PgVLufd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Load Datasets"
      ],
      "metadata": {
        "id": "VR-cijeNkMhK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_file = \"/content/Hazards_LABELLED_TRAIN (1).csv\"\n",
        "test_file = \"/content/Hazards_UNLABELLED_TEST (1).csv\"\n",
        "df_train = pd.read_csv(train_file)\n",
        "df_test = pd.read_csv(test_file)"
      ],
      "metadata": {
        "id": "jPCyQZ0yjXCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Combine Title and Text"
      ],
      "metadata": {
        "id": "RMsy_qklkT8z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train[\"full-text\"] = df_train[\"title\"].fillna('') + \" \" + df_train[\"text\"].fillna('')\n",
        "df_test[\"full-text\"] = df_test[\"title\"].fillna('') + \" \" + df_test[\"text\"].fillna('')"
      ],
      "metadata": {
        "id": "W5XCy0POjadK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Encode Categorical Variables"
      ],
      "metadata": {
        "id": "q7jJznmQkWoC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoders = {}\n",
        "for col in [\"country\", \"hazard-type\", \"product-category\"]:\n",
        "    label_encoders[col] = LabelEncoder()\n",
        "    if col in df_train.columns:\n",
        "        df_train[col] = label_encoders[col].fit_transform(df_train[col])\n",
        "    if col in df_test.columns and col != \"hazard-type\" and col != \"product-category\":\n",
        "        # For 'country', handle unseen countries in test set\n",
        "        known_countries = set(label_encoders['country'].classes_)\n",
        "        df_test['country'] = df_test['country'].apply(\n",
        "            lambda x: x if x in known_countries else label_encoders['country'].classes_[0]\n",
        "        )\n",
        "        df_test['country'] = label_encoders['country'].transform(df_test['country'])"
      ],
      "metadata": {
        "id": "5Lquk1VtjewT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Feature Engineering (optional)"
      ],
      "metadata": {
        "id": "ju6bwC1CkZ0E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train[\"text_len\"] = df_train[\"full-text\"].apply(len)\n",
        "df_test[\"text_len\"] = df_test[\"full-text\"].apply(len)"
      ],
      "metadata": {
        "id": "KmjgWDymjiBU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. TF-IDF Vectorization (fit on train, transform on both)"
      ],
      "metadata": {
        "id": "_Fc9MjIwkeXG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf = TfidfVectorizer(\n",
        "    max_features=20000,\n",
        "    ngram_range=(1, 3),\n",
        "    stop_words='english',\n",
        "    sublinear_tf=True\n",
        ")\n",
        "X_text_train = tfidf.fit_transform(df_train[\"full-text\"]).toarray()\n",
        "X_text_test = tfidf.transform(df_test[\"full-text\"]).toarray()"
      ],
      "metadata": {
        "id": "eW-afXw4jkej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Prepare Structured Features"
      ],
      "metadata": {
        "id": "CbEhotA8khp0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "struct_cols = [\"year\", \"month\", \"day\", \"country\", \"text_len\"]\n",
        "X_struct_train = df_train[struct_cols].values\n",
        "X_struct_test = df_test[struct_cols].values"
      ],
      "metadata": {
        "id": "QHwZD29LjnSD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. Merge Structured and Text Features"
      ],
      "metadata": {
        "id": "Kur92A0Akkg1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.hstack((X_struct_train, X_text_train))\n",
        "X_test = np.hstack((X_struct_test, X_text_test))\n",
        "\n",
        "y_hazard = df_train[\"hazard-type\"].values\n",
        "y_product = df_train[\"product-category\"].values"
      ],
      "metadata": {
        "id": "vqf4D_H-jp6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9. Compute Class Weights (for hazard and product)"
      ],
      "metadata": {
        "id": "afjZp72vknGl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_weights_hazard = compute_class_weight('balanced', classes=np.unique(y_hazard), y=y_hazard)\n",
        "class_weights_product = compute_class_weight('balanced', classes=np.unique(y_product), y=y_product)\n",
        "weights_hazard = np.array([class_weights_hazard[label] for label in y_hazard])\n",
        "weights_product = np.array([class_weights_product[label] for label in y_product])"
      ],
      "metadata": {
        "id": "LHb-Kp9YjsOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10. Split Train/Validation for Local Validation"
      ],
      "metadata": {
        "id": "cbbuqanrkp7H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_tr, X_val, y_tr_hazard, y_val_hazard, y_tr_product, y_val_product, w_tr_hazard, w_val_hazard, w_tr_product, w_val_product = train_test_split(\n",
        "    X_train, y_hazard, y_product, weights_hazard, weights_product, test_size=0.2, random_state=42, stratify=y_hazard\n",
        ")"
      ],
      "metadata": {
        "id": "hVgTAIH6jufF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 11. LightGBM Datasets"
      ],
      "metadata": {
        "id": "JL09_4cIkseB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_hazard = lgb.Dataset(X_tr, label=y_tr_hazard, weight=w_tr_hazard)\n",
        "val_data_hazard = lgb.Dataset(X_val, label=y_val_hazard, weight=w_val_hazard)\n",
        "train_data_product = lgb.Dataset(X_tr, label=y_tr_product, weight=w_tr_product)\n",
        "val_data_product = lgb.Dataset(X_val, label=y_val_product, weight=w_val_product)"
      ],
      "metadata": {
        "id": "xpEEdigfjxNV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 12. LightGBM Parameters"
      ],
      "metadata": {
        "id": "DTHXj4aDku9g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params = {\n",
        "    'objective': 'multiclass',\n",
        "    'metric': 'multi_logloss',\n",
        "    'boosting_type': 'gbdt',\n",
        "    'num_leaves': 128,\n",
        "    'learning_rate': 0.03,\n",
        "    'max_depth': 24,\n",
        "    'feature_fraction': 0.9,\n",
        "    'bagging_fraction': 0.9,\n",
        "    'bagging_freq': 3,\n",
        "    'lambda_l1': 2.0,\n",
        "    'lambda_l2': 2.0,\n",
        "    'verbose': -1\n",
        "}\n",
        "params_hazard = params.copy()\n",
        "params_hazard['num_class'] = len(np.unique(y_hazard))\n",
        "params_product = params.copy()\n",
        "params_product['num_class'] = len(np.unique(y_product))"
      ],
      "metadata": {
        "id": "ACVjtBDNjzlk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 13. Train Hazard Model"
      ],
      "metadata": {
        "id": "GHS5KmdUkynI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_hazard = lgb.train(\n",
        "    params_hazard,\n",
        "    train_data_hazard,\n",
        "    num_boost_round=1500,\n",
        "    valid_sets=[val_data_hazard],\n",
        "    callbacks=[lgb.early_stopping(stopping_rounds=100), lgb.log_evaluation(100)]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jyTpx6noj2fl",
        "outputId": "b9543079-ad91-44f4-c0fa-c842ec148407"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\tvalid_0's multi_logloss: 0.881874\n",
            "Early stopping, best iteration is:\n",
            "[75]\tvalid_0's multi_logloss: 0.852054\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 14. Train Product Model"
      ],
      "metadata": {
        "id": "gIDx5aDWk13a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_product = lgb.train(\n",
        "    params_product,\n",
        "    train_data_product,\n",
        "    num_boost_round=1500,\n",
        "    valid_sets=[val_data_product],\n",
        "    callbacks=[lgb.early_stopping(stopping_rounds=100), lgb.log_evaluation(100)]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iN7_SnKIj4nW",
        "outputId": "570adb53-dad7-4c5d-9dc7-f6ab777669c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\tvalid_0's multi_logloss: 1.6501\n",
            "[200]\tvalid_0's multi_logloss: 1.68671\n",
            "Early stopping, best iteration is:\n",
            "[114]\tvalid_0's multi_logloss: 1.64363\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 15. Validation F1 Score (optional, for your reference)"
      ],
      "metadata": {
        "id": "uLq3wS_Gk5g_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_hazard_val = np.argmax(model_hazard.predict(X_val, num_iteration=model_hazard.best_iteration), axis=1)\n",
        "y_pred_product_val = np.argmax(model_product.predict(X_val, num_iteration=model_product.best_iteration), axis=1)\n",
        "macro_f1_hazard = f1_score(y_val_hazard, y_pred_hazard_val, average='macro')\n",
        "macro_f1_product = f1_score(y_val_product, y_pred_product_val, average='macro')\n",
        "print(f\"Validation Macro F1-score (Hazard Type): {macro_f1_hazard:.4f}\")\n",
        "print(f\"Validation Macro F1-score (Product Category): {macro_f1_product:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8DdUBhij6Kf",
        "outputId": "602b8e11-85e6-4db7-c304-39bb22d973fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Macro F1-score (Hazard Type): 0.7189\n",
            "Validation Macro F1-score (Product Category): 0.4470\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 16. Predict on Test Set"
      ],
      "metadata": {
        "id": "AQpG-FOHk8fZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preds_hazard_test = model_hazard.predict(X_test, num_iteration=model_hazard.best_iteration)\n",
        "preds_product_test = model_product.predict(X_test, num_iteration=model_product.best_iteration)\n",
        "pred_labels_hazard = np.argmax(preds_hazard_test, axis=1)\n",
        "pred_labels_product = np.argmax(preds_product_test, axis=1)"
      ],
      "metadata": {
        "id": "C4XClRd-j-Vo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 17. Decode labels to original strings"
      ],
      "metadata": {
        "id": "ejUJr-3hk_mb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred_hazard = label_encoders['hazard-type'].inverse_transform(pred_labels_hazard)\n",
        "pred_product = label_encoders['product-category'].inverse_transform(pred_labels_product)"
      ],
      "metadata": {
        "id": "d-J90XopkAiQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 18. Create Submission DataFrame"
      ],
      "metadata": {
        "id": "CMcg01djlCTh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "submission = pd.DataFrame({\n",
        "    'ID': df_test['ID'],\n",
        "    'hazard': pred_hazard,\n",
        "    'product': pred_product\n",
        "})\n",
        "\n",
        "submission.to_csv('submission.csv', index=False, encoding='utf-8')\n",
        "print(\"Submission file 'submission.csv' created successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "724tPbRpkCDI",
        "outputId": "fc45be39-38f0-4c4a-e243-1aa680de4501"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submission file 'submission.csv' created successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('submission.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "obHVyu30kEb5",
        "outputId": "dd5c4cb6-ee82-4411-f405-7d66eaf93382"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_d979a8ae-e0b3-4b0e-8557-e59ebbea68d9\", \"submission.csv\", 47493)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}